{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music_genre_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBXsr-e9h5Kr"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import keras.backend as K\n",
        "from pydub import AudioSegment\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers\n",
        "from keras.layers import (Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, \n",
        "                          Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout)\n",
        "from keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPbftx1Xdibc"
      },
      "source": [
        "os.makedirs('audio/genres', exist_ok=True)\n",
        "\n",
        "df_tracks = pd.read_csv('gdrive/My Drive/tracks.csv', header=1)\n",
        "df_tracks.rename(columns = {df_tracks.columns[0]:df_tracks.iloc[0][0]}, inplace=True)\n",
        "df_tracks.drop(labels=0, axis=0, inplace=True)\n",
        "df_tracks = df_tracks[['track_id', 'genre_top']]\n",
        "df_tracks['track_id'] = df_tracks['track_id'].astype('str')\n",
        "\n",
        "lst_track_id = list()\n",
        "for folder in os.listdir('audio/fma_small'):\n",
        "    if folder.isnumeric():\n",
        "        for filename in os.listdir(os.path.join('audio/fma_small', folder)):\n",
        "            if filename.split('.')[0].isnumeric():\n",
        "                lst_track_id.append(str(int(filename.split('.')[0])))\n",
        "df_track_id = pd.DataFrame({'track_id':lst_track_id})\n",
        "\n",
        "df_track_genres = pd.merge(df_track_id, df_tracks, on='track_id')\n",
        "\n",
        "genres = 'Hip-Hop Electronic Instrumental International Folk Rock Experimental Pop'.split()\n",
        "\n",
        "for g in genres:\n",
        "    os.makedirs(os.path.join('audio/genres', g), exist_ok=True)\n",
        "\n",
        "lst_track_id = list()\n",
        "for folder in os.listdir('audio/fma_small'):\n",
        "    if folder.isnumeric():\n",
        "        for filename in os.listdir(os.path.join('audio/fma_small', folder)):\n",
        "            if filename.split('.')[0].isnumeric():\n",
        "                \n",
        "                g = df_track_genres.loc[df_track_genres['track_id'] == str(int(filename.split('.')[0]))]['genre_top'].iloc[0]\n",
        "              \n",
        "                try:  \n",
        "                    song = AudioSegment.from_mp3(os.path.join('audio/fma_small', folder, filename))\n",
        "                except:\n",
        "                  pass\n",
        "                \n",
        "                for w in range(10):\n",
        "                    \n",
        "                    t1 = 3*w*1000  \n",
        "                    t2 = 3*(w+1)*1000\n",
        "                    \n",
        "                    songSegment = song[t1:t2]\n",
        "\n",
        "                    songSegment.export(f'audio/genres/{g}/{filename}_{str(w)}.wav', format='wav')                "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoOek8gm0cBG"
      },
      "source": [
        "os.makedirs('audio/spectrograms', exist_ok=True)\n",
        "\n",
        "for g in genres:\n",
        "  os.makedirs(f'audio/spectrograms/{g}', exist_ok=True)\n",
        "\n",
        "for g in genres:\n",
        "    \n",
        "    i = 0\n",
        "    for audio_3s_file in os.listdir(f'audio/genres/{g}'):\n",
        "        try:\n",
        "          i+=1\n",
        "          \n",
        "          y, sr=librosa.load(os.path.join(f'audio/genres/{g}', audio_3s_file), duration=3)\n",
        "        except:\n",
        "          pass\n",
        "        \n",
        "        try:\n",
        "          mels = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "        except:\n",
        "          pass\n",
        "        \n",
        "        fig = plt.Figure()\n",
        "        p = plt.imshow(librosa.power_to_db(mels,ref=np.max))\n",
        "\n",
        "        plt.savefig(f'audio/spectrograms/{g}/' + audio_3s_file.split('.')[0] + '.png')\n",
        "        \n",
        "        if i == 250:\n",
        "          break\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZggcjPgV9En"
      },
      "source": [
        "os.makedirs('audio/train', exist_ok=True)\n",
        "os.makedirs('audio/test', exist_ok=True)\n",
        "\n",
        "for g in genres:\n",
        "  os.makedirs(f'audio/train/{g}', exist_ok=True)\n",
        "\n",
        "for g in genres:\n",
        "  for spec_file in os.listdir(f'audio/spectrograms/{g}'):\n",
        "    shutil.copy(os.path.join(f'audio/spectrograms/{g}', spec_file), os.path.join(f'audio/train/{g}/', spec_file))\n",
        "\n",
        "for g in genres:\n",
        "  os.makedirs(f'audio/test/{g}', exist_ok=True)\n",
        "  spectrogram_files = os.listdir(f'audio/train/{g}')\n",
        "  random.shuffle(spectrogram_files)\n",
        "  test_spec_files = spectrogram_files[0:int(0.1*len(spectrogram_files))]\n",
        "  for spec_file in test_spec_files:\n",
        "    shutil.move(os.path.join(f'audio/train/{g}', spec_file), f'audio/test/{g}')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymlga8Z6X0qA",
        "outputId": "8a55bdec-4579-4153-a2b6-9986b0b03cb5"
      },
      "source": [
        "train_dir = \"audio/train/\"\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(288,432),color_mode=\"rgba\",class_mode='categorical',batch_size=128)\n",
        "\n",
        "validation_dir = \"audio/test/\"\n",
        "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
        "vali_generator = vali_datagen.flow_from_directory(validation_dir,target_size=(288,432),color_mode='rgba',class_mode='categorical',batch_size=128)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1610 images belonging to 8 classes.\n",
            "Found 175 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-LdIhsYYOF2"
      },
      "source": [
        "def GenreModel(input_shape = (288,432,4),classes=8):\n",
        "  \n",
        "  X_input = Input(input_shape)\n",
        "\n",
        "  X = Conv2D(8,kernel_size=(3,3),strides=(1,1))(X_input)\n",
        "  X = BatchNormalization(axis=3)(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((2,2))(X)\n",
        "  \n",
        "  X = Conv2D(16,kernel_size=(3,3),strides = (1,1))(X)\n",
        "  X = BatchNormalization(axis=3)(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((2,2))(X)\n",
        "  \n",
        "  X = Conv2D(32,kernel_size=(3,3),strides = (1,1))(X)\n",
        "  X = BatchNormalization(axis=3)(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((2,2))(X)\n",
        "\n",
        "  X = Conv2D(64,kernel_size=(3,3),strides=(1,1))(X)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((2,2))(X)\n",
        "  \n",
        "  X = Conv2D(128,kernel_size=(3,3),strides=(1,1))(X)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((2,2))(X)\n",
        "\n",
        "  \n",
        "  X = Flatten()(X)\n",
        "  \n",
        "  X = Dropout(rate=0.3)(X)\n",
        "\n",
        "  X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
        "\n",
        "  model = Model(inputs=X_input,outputs=X,name='GenreModel')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9V4kj9iwy4L"
      },
      "source": [
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "  \n",
        "model = GenreModel(input_shape=(288,432,4),classes=8)\n",
        "opt = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer = opt,loss='categorical_crossentropy',metrics=['accuracy',get_f1]) \n",
        "\n",
        "model.fit_generator(train_generator,epochs=70,validation_data=vali_generator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}